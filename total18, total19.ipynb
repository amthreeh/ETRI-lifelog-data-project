{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a40fda-bddd-45db-bc3a-7b062670d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score #Confusion matrix 수업 때 진행할 예정 \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3882ddb8-fbd5-4f52-9eb1-ecb1614db918",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2018&2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8db842-de72-4609-9b55-1fdd036fabd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sh/lab/etritf/jw_data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7daf46-d508-4269-844b-e36d5fa1b22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sh/lab/etritf\n"
     ]
    }
   ],
   "source": [
    "cd /home/sh/lab/etritf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56193f56-db15-451f-b8ec-32019cd333f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('ja_data/total1819.csv').drop(['Unnamed: 0.1','Unnamed: 0'],axis=1)\n",
    "data=data.fillna(-1)\n",
    "data18=data[data['device']=='Fitbit']\n",
    "data19=data[data['device']=='Actigraph']\n",
    "len(data18['userId'].unique()),len(data19['userId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c7ddf93-76ec-448d-9c4c-2715a4eb3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('ja_data/total1819.csv').drop(['Unnamed: 0.1','Unnamed: 0'],axis=1)\n",
    "data=data.fillna(-1)\n",
    "data18=data[data['device']=='Fitbit']\n",
    "list18 =list(data18['userId'].unique())\n",
    "# userId가 같은 것끼리 데이터프레임 만들기\n",
    "for i in range(len(list18)):\n",
    "    # if data18['userId'] == list18[i]:\n",
    "    df18 = pd.DataFrame(data18[data18['userId'] == list18[i]])\n",
    "    #print(list18[i])\n",
    "    df18.to_csv('jw_data/total18/'+f'{list18[i]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8ca72f52-8fb6-4200-8595-986bafadecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('ja_data/total1819.csv').drop(['Unnamed: 0.1','Unnamed: 0'],axis=1)\n",
    "data=data.fillna(-1)\n",
    "data19=data[data['device']=='Actigraph']\n",
    "list19 =list(data19['userId'].unique())\n",
    "print(list19)\n",
    "# userId가 같은 것끼리 데이터프레임 만들기\n",
    "for i in range(len(list19)):\n",
    "    data19 = pd.DataFrame(data[data['userId'] == list19[i]])\n",
    "    print\n",
    "    data19.to_csv('jw_data/data19/'+f'{list19[i]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9269fbb6-c360-44a4-8ece-0fc6aca1fbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', '102.csv', '104.csv', '105.csv', '106.csv', '107.csv', '108.csv', '109.csv', '110.csv', '111.csv', '112.csv', '113.csv', '114.csv', '115.csv', '118.csv', '119.csv', '120.csv']\n",
      "------- 101.csv ------------------------------------\n",
      "------- 102.csv ------------------------------------\n",
      "------- 103.csv ------------------------------------\n",
      "------- 104.csv ------------------------------------\n",
      "------- 105.csv ------------------------------------\n",
      "------- 106.csv ------------------------------------\n",
      "------- 107.csv ------------------------------------\n",
      "------- 108.csv ------------------------------------\n",
      "------- 109.csv ------------------------------------\n",
      "------- 110.csv ------------------------------------\n",
      "------- 111.csv ------------------------------------\n",
      "------- 112.csv ------------------------------------\n",
      "------- 113.csv ------------------------------------\n",
      "------- 114.csv ------------------------------------\n",
      "------- 115.csv ------------------------------------\n",
      "------- 116.csv ------------------------------------\n"
     ]
    }
   ],
   "source": [
    "action_list =['sleep', 'personal_care', 'work', 'study', 'household', \n",
    "              'recreation_media', 'entertainment', 'outdoor_act', 'hobby', 'recreation_etc', \n",
    "              'communitiy_interaction', 'travel', 'meal', 'socialising']\n",
    "DIRNAME =sorted(os.listdir('jw_data/2019_label_date/'))\n",
    "sleep_dirname = sorted(os.listdir('jw_data/data19/'))\n",
    "diff_files = [file for file in DIRNAME if file in sleep_dirname]\n",
    "print(diff_files)\n",
    "action_option = []\n",
    "for i in range(len(diff_files)):\n",
    "    if diff_files[i] == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    else:\n",
    "        base_dir1 = 'jw_data/2019_label_date/'+diff_files[i]\n",
    "        base_dir2 = 'jw_data/data19/'+diff_files[i]\n",
    "        label_data = pd.read_csv(base_dir1)\n",
    "        sleep_data = pd.read_csv(base_dir2)\n",
    "        datelist = sorted(label_data['date'].unique())\n",
    "        df =pd.get_dummies(label_data['action'])\n",
    "        action_df = pd.DataFrame(columns= action_list)\n",
    "        score = sleep_data[['pmEmotion', 'pmStress',\n",
    "       'ifUnusual', 'breakfast', 'lunch', 'dinner', 'lateSnack', 'amCaffeine',\n",
    "       'amCaffAmount', 'pmCaffeine', 'pmCaffAmount', 'alcohol', 'aAmount',\n",
    "       'date', 'sleep', 'inputDt', 'sleepProblem', 'dream', 'amCondition',\n",
    "       'amEmotion', 'total_CaffAmount', 'date_m', 'startDt', 'endDt', \n",
    "       'sleep_score', 'total_sleep_time', 'time_in_bed', 'waso', 'wakeupcount',\n",
    "       'aal', 'movement_index', 'fragmentation_index', 'sleep_frag_index']]\n",
    "       \n",
    "        print(\"-------\", f\"{DIRNAME[i]}\", \"------------------------------------\")\n",
    "        for j in range(len(datelist)):\n",
    "            action = pd.DataFrame(data = label_data[label_data['date'] == datelist[j]][-180:], columns =['date','action'])\n",
    "            action_num_list = action['action'].unique() # 해당 날짜에 수행한 action 리스트\n",
    "            #print(action_num_list)\n",
    "            date = action['date'].unique()\n",
    "            date_action_dict = dict(zip(date, [action_num_list])) # 날짜와 해당하는 action\n",
    "            for date, action in date_action_dict.items():\n",
    "                action_df.loc[date, action] = 1\n",
    "               \n",
    "        action_df = action_df.fillna(0)\n",
    "        action_df = action_df.reset_index(drop=True)\n",
    "        score = score.reset_index(drop=True)\n",
    "        \n",
    "        merged_df = pd.concat([action_df, score], axis=1, join='inner')\n",
    "        merged_df.to_csv('jw_data/total19/'+f\"{diff_files[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fadb803-7b58-4102-ab59-d580c4846a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1.csv ------------------------------------\n",
      "------- 10.csv ------------------------------------\n",
      "------- 11.csv ------------------------------------\n",
      "------- 12.csv ------------------------------------\n",
      "------- 13.csv ------------------------------------\n",
      "------- 14.csv ------------------------------------\n",
      "------- 15.csv ------------------------------------\n",
      "------- 16.csv ------------------------------------\n",
      "------- 17.csv ------------------------------------\n",
      "------- 18.csv ------------------------------------\n",
      "------- 19.csv ------------------------------------\n",
      "------- 2.csv ------------------------------------\n",
      "------- 20.csv ------------------------------------\n",
      "------- 21.csv ------------------------------------\n",
      "------- 22.csv ------------------------------------\n",
      "------- 23.csv ------------------------------------\n",
      "------- 24.csv ------------------------------------\n",
      "------- 25.csv ------------------------------------\n",
      "------- 26.csv ------------------------------------\n",
      "------- 27.csv ------------------------------------\n",
      "------- 28.csv ------------------------------------\n",
      "------- 29.csv ------------------------------------\n",
      "------- 3.csv ------------------------------------\n",
      "------- 30.csv ------------------------------------\n",
      "------- 4.csv ------------------------------------\n",
      "------- 5.csv ------------------------------------\n",
      "------- 6.csv ------------------------------------\n",
      "------- 7.csv ------------------------------------\n",
      "------- 8.csv ------------------------------------\n",
      "------- 9.csv ------------------------------------\n"
     ]
    }
   ],
   "source": [
    "action_list =['sleep', 'personal_care', 'work', 'study', 'household', \n",
    "              'recreation_media', 'entertainment', 'outdoor_act', 'hobby', 'recreation_etc', \n",
    "              'communitiy_interaction', 'travel', 'meal', 'socialising']\n",
    "DIRNAME =sorted(os.listdir('jw_data/2018_label_date/'))\n",
    "sleep_dirname = sorted(os.listdir('jw_data/data18/'))\n",
    "diff_files = [file for file in DIRNAME if file in sleep_dirname]\n",
    "\n",
    "action_option = []\n",
    "for i in range(len(diff_files)):\n",
    "    if diff_files[i] == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    else:\n",
    "        base_dir1 = 'jw_data/2018_label_date/'+diff_files[i]\n",
    "        base_dir2 = 'jw_data/data18/'+diff_files[i]\n",
    "        label_data = pd.read_csv(base_dir1)\n",
    "        sleep_data = pd.read_csv(base_dir2)\n",
    "        datelist = sorted(label_data['date'].unique())\n",
    "        df =pd.get_dummies(label_data['action'])\n",
    "        action_df = pd.DataFrame(columns= action_list)\n",
    "        score = sleep_data[['pmEmotion', 'pmStress',\n",
    "       'ifUnusual', 'breakfast', 'lunch', 'dinner', 'lateSnack', 'amCaffeine',\n",
    "       'amCaffAmount', 'pmCaffeine', 'pmCaffAmount', 'alcohol', 'aAmount',\n",
    "       'date', 'sleep', 'inputDt', 'sleepProblem', 'dream', 'amCondition',\n",
    "       'amEmotion', 'total_CaffAmount', 'date_m', 'startDt', 'endDt', \n",
    "       'sleep_score', 'total_sleep_time', 'time_in_bed', 'waso', 'wakeupcount',\n",
    "       'aal', 'movement_index', 'fragmentation_index', 'sleep_frag_index']]\n",
    "       \n",
    "        print(\"-------\", f\"{DIRNAME[i]}\", \"------------------------------------\")\n",
    "        for j in range(len(datelist)):\n",
    "            action = pd.DataFrame(data = label_data[label_data['date'] == datelist[j]][-180:], columns =['date','action'])\n",
    "            action_num_list = action['action'].unique() # 해당 날짜에 수행한 action 리스트\n",
    "            #print(action_num_list)\n",
    "            date = action['date'].unique()\n",
    "            date_action_dict = dict(zip(date, [action_num_list])) # 날짜와 해당하는 action\n",
    "            for date, action in date_action_dict.items():\n",
    "                action_df.loc[date, action] = 1\n",
    "               \n",
    "        action_df = action_df.fillna(0)\n",
    "        action_df = action_df.reset_index(drop=True)\n",
    "        score = score.reset_index(drop=True)\n",
    "        \n",
    "        merged_df = pd.concat([action_df, score], axis=1, join='inner')\n",
    "        merged_df.to_csv('jw_data/total18/'+f\"{diff_files[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e3650d5-faf3-4f87-be71-9fa21927d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DIRNAME = sorted(os.listdir('jw_data/total18/'))\n",
    "dfs = []\n",
    "for i in range(len(DIRNAME)):\n",
    "    if DIRNAME[i] == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    else:\n",
    "        base_dir1 = 'jw_data/total18/'+DIRNAME[i]\n",
    "        action_label_data = pd.read_csv(base_dir1)\n",
    "        dfs.append(action_label_data)\n",
    "   \n",
    "\n",
    "merged_dfs = pd.concat(dfs, ignore_index=False) \n",
    "merged_dfs.to_csv('jw_data/total18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e9601e17-c7e7-46bd-8a69-3bca55d27d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DIRNAME = sorted(os.listdir('jw_data/total19/'))\n",
    "dfs = []\n",
    "for i in range(len(DIRNAME)):\n",
    "    if DIRNAME[i] == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    else:\n",
    "        base_dir1 = 'jw_data/total19/'+DIRNAME[i]\n",
    "        action_label_data = pd.read_csv(base_dir1)\n",
    "        dfs.append(action_label_data)\n",
    "   \n",
    "\n",
    "merged_dfs = pd.concat(dfs, ignore_index=False) \n",
    "merged_dfs.to_csv('jw_data/total19.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etritf",
   "language": "python",
   "name": "etritf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
